# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

This project will develop a set of JarRunner adapters to perform the following
tasks via specific adapters:
  - provide a list of files within a jar file (artifact) which can be passed to a test
    framework such as JUnit for further execution (generic adapter)
  - request a list of tests from an artifact to be execute by an external
    framework (specific adapter)
  - get a list of tests within an artifact, supply them with certain arguments
    and run as POJO applications (concrete adapter: an extension of generic)

This project contains the experimental foundation of JarRunner and a
meta-service utilizing it to perform tests execution. These two components
might be joined together later.

New cluster failures injection capabilities for smoke tests (see BIGTOP-1192 for details)
imposed certain additional requirements. Smoke tests running cluster failures against real clusters
expect the following preconditions to be satistied:
  - For all hosts in the cluster being smoke-tested there's a dedicated user(like "jenkins" or "bigtop"),
    which has password-less SSH access to those hosts and permissions to execute certain sudo commands
    (see below) without password
  - 2 new environment variable are set:
      * BIGTOP_SMOKES_USER should contain username of user which will be used to run SSH commands
      * BIGTOP_SMOKES_CLUSTER_IDENTITY_FILE should point to a file with private key for password-less SSH.

To be able to run new itest framework internal test (see ClusterFailuresTest.groovy), the following change
is needed on the machine with Bigtop workspace:
 - if your current user doesn't have password-less sude, then run 'visudo' and:
     * add line in /etc/sudoers at the end of file like: (for Redhat):
       myusername  localhost = NOPASSWD:/usr/sbin/service,/usr/bin/pkill,/usr/sbin/iptables

To be able to run real module smoke tests again real cluster, more complex setup is needed
on the machine with Bigtop workspace:
 - make sure sshd is all nodes in the cluster
 - check the following in /etc/ssh/sshd_config:
     * PubkeyAuthentication yes
     * PasswordAuthentication yes
 - add new user, for example, "bigtop", on local machine AND on each cluster node, set some password,
   make sure default shell is set
 - on local machine, su bigtop, do ssh-keygen with empty passphrase
 - run 'ssh-copy-id bigtop@<each cluster node>'
 - log back in on your local machine as your regular user which you use to work with your workspace, copy the generated private
   key for bigtop user somewhere, do chown and make sure it has right permissions (like 600)
 - export BIGTOP_SMOKES_CLUSTER_IDENTITY_FILE=/full/path/to/private/key
 - export BIGTOP_SMOKES_USER=bigtop
 - on each remote node, run 'visudo' and
     * add line in /etc/sudoers at the end of file like: (for Redhat):
       bigtop  localhost = NOPASSWD:/usr/sbin/service,/usr/bin/pkill,/usr/sbin/iptables
     * Comment out line 'Defaults    requiretty', otherwise sudo may complain like
       "Sorry, you must have a tty to run sudo"

  - run following sample commands from your local machine to verify your setup:
      * ssh -i /test_bigtop_ssh_key bigtop@<some cluster node> sudo service crond stop
      * ssh -i /test_bigtop_ssh_key bigtop@<some cluster node> sudo service crond start

The user can now run a series of cluster failures while running hadoop and mapreduce tests. This can be achieved by
modifying the vars.properties file found in src/main/resources. To enable the properties file, use -DuseProperties=true
when running tests (ex: mvn verify -f bigtop-tests/test-execution/longevity/pom.xml -DuseProperties=true
-Dorg.apache.maven-failsafe-plugin.testInclude=**/TestDFSIO*/).

For vars.properties:
-Use testhost=name to specify host being tested on.
-Use testremotehost=name to specify remote host name being tested on.
-Use runall=true to run all cluster failures.
-Use servicerestart=true to perform a cron or crond service restart.
-Use servicekill=true to perform a service kill.
-Use networkshutdown=true to perform network shutdown and restart.
-Use service=name to specify which service being used for restart/kill. (default is crond).
-Use failuredelay=time to specify time (in seconds) in between each failure function.
-Use startdelay=time to specify time (in seconds) before first failure.
-Use killduration=time to specify the duration (in seconds) a service is down for.