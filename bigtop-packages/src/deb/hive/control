# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

Source: hive
Section: misc
Priority: extra
Maintainer: Bigtop <dev@bigtop.apache.org>
Build-Depends: debhelper (>= 7.0.50~)
Standards-Version: 3.9.4
Homepage: http://hive.apache.org/


Package: hive${CRH_VERSION_AS_NAME}
Architecture: all
Depends: adduser, hadoop${CRH_VERSION_AS_NAME}-client, bigtop-utils (>= 0.7), zookeeper${CRH_VERSION_AS_NAME}, hive${CRH_VERSION_AS_NAME}-jdbc (= ${source:Version}), python
Description: Hive is a data warehouse infrastructure built on top of Hadoop
 Hive is a data warehouse infrastructure built on top of Hadoop that provides
 tools to enable easy data summarization, adhoc querying and analysis of large
 datasets data stored in Hadoop files. It provides a mechanism to put structure
 on this data and it also provides a simple query language called Hive QL which
 is based on SQL and which enables users familiar with SQL to query this data.
 At the same time, this language also allows traditional map/reduce programmers
 to be able to plug in their custom mappers and reducers to do more sophisticated 
 analysis which may not be supported by the built-in capabilities of the language.

Package: hive${CRH_VERSION_AS_NAME}-server2
Architecture: all
Depends: hive${CRH_VERSION_AS_NAME} (= ${source:Version})
Description: Provides a Hive Thrift service with improved concurrency support.
 This optional package hosts a Thrift server for Hive clients across a network to use, with improved concurrency support.

Package: hive${CRH_VERSION_AS_NAME}-metastore
Architecture: all
Depends: hive${CRH_VERSION_AS_NAME} (= ${source:Version})
Description: Shared metadata repository for Hive.
 This optional package hosts a metadata server for Hive clients across a network to use.

Package: hive${CRH_VERSION_AS_NAME}-hbase
Architecture: all
Depends: hive${CRH_VERSION_AS_NAME} (= ${source:Version}), hbase${CRH_VERSION_AS_NAME}
Description: Provides integration between Apache HBase and Apache Hive
 This optional package provides integration between Apache HBase and Apache Hive

Package: hive${CRH_VERSION_AS_NAME}-jdbc
Architecture: all
Depends: hadoop${CRH_VERSION_AS_NAME}-client
Description: Provides libraries necessary to connect to Apache Hive via JDBC
 This package provides libraries necessary to connect to Apache Hive via JDBC

Package: hive${CRH_VERSION_AS_NAME}-hcatalog
Architecture: all
Depends: hadoop${CRH_VERSION_AS_NAME}, hive${CRH_VERSION_AS_NAME}, bigtop-utils (>= 0.6), python
Description: Apache Hcatalog is a data warehouse infrastructure built on top of Hadoop
 Apache HCatalog is a table and storage management service for data created using Apache Hadoop.
 This includes:
   * Providing a shared schema and data type mechanism.
   * Providing a table abstraction so that users need not be concerned with where or how their data is stored.
   * Providing interoperability across data processing tools such as Pig, Map Reduce, Streaming, and Hive.

Package: hive${CRH_VERSION_AS_NAME}-hcatalog-server
Architecture: all
Depends: hive${CRH_VERSION_AS_NAME}-hcatalog (= ${source:Version})
Description: Init scripts for HCatalog server
 Init scripts for HCatalog server

Package: hive${CRH_VERSION_AS_NAME}-webhcat
Architecture: all
Depends: hive${CRH_VERSION_AS_NAME}-hcatalog (= ${source:Version})
Description: WebHcat provides a REST-like web API for HCatalog and related Hadoop components.
 WebHcat provides a REST-like web API for HCatalog and related Hadoop components.

Package: hive${CRH_VERSION_AS_NAME}-webhcat-server
Architecture: all
Depends: hive${CRH_VERSION_AS_NAME}-webhcat (= ${source:Version})
Description: Init scripts for WebHcat server
 Init scripts for WebHcat server.
