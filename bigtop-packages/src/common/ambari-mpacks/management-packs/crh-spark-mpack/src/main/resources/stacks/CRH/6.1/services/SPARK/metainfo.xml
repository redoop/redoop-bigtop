<?xml version="1.0"?>
<!--
/**
 * Licensed to the Apache Software Foundation (ASF) under one
 * or more contributor license agreements.  See the NOTICE file
 * distributed with this work for additional information
 * regarding copyright ownership.  The ASF licenses this file
 * to you under the Apache License, Version 2.0 (the
 * "License"); you may not use this file except in compliance
 * with the License.  You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */
-->
<metainfo>
  <schemaVersion>2.0</schemaVersion>
  <services>
    <service>
      <name>SPARK</name>
      <comment>Apache Spark is a fast and general engine for large-scale data processing</comment>
      <version>2.2.0</version>
      <!--<extends>6.0/services/SPARK</extends>-->
      <selection>DEFAULT</selection>

      <components>
        <component>
          <name>LIVY2_SERVER</name>
          <displayName>Livy for Spark Server</displayName>
          <category>SLAVE</category>
          <cardinality>0+</cardinality>
          <versionAdvertised>true</versionAdvertised>
          <dependencies>
            <dependency>
              <name>SPARK/SPARK_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
              <name>HDFS/HDFS_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
            <dependency>
              <name>YARN/YARN_CLIENT</name>
              <scope>host</scope>
              <auto-deploy>
                <enabled>true</enabled>
              </auto-deploy>
            </dependency>
          </dependencies>
          <commandScript>
            <script>scripts/livy2_server.py</script>
            <scriptType>PYTHON</scriptType>
            <timeout>600</timeout>
          </commandScript>
          <logs>
            <log>
              <logId>livy2_server</logId>
              <primary>true</primary>
            </log>
          </logs>
        </component>
      </components>
      <configuration-dependencies>
        <config-type>spark-defaults</config-type>
        <config-type>spark-env</config-type>
        <config-type>spark-log4j-properties</config-type>
        <config-type>spark-metrics-properties</config-type>
        <config-type>spark-thrift-sparkconf</config-type>
        <config-type>spark-hive-site-override</config-type>
        <config-type>spark-thrift-fairscheduler</config-type>
        <config-type>livy2-conf</config-type>
        <config-type>livy2-env</config-type>
        <config-type>livy2-log4j-properties</config-type>
        <config-type>livy2-spark-blacklist</config-type>
      </configuration-dependencies>

      <osSpecifics>
        <osSpecific>
          <osFamily>redhat7,amazon2015,redhat6,suse11,suse12</osFamily>
          <packages>
            <package>
              <name>spark_${stack_version}</name>
            </package>
            <package>
              <name>spark_${stack_version}-python</name>
            </package>
            <!-- should install spark2_${stack_version}-datanucleus -->
            <package>
              <name>spark_${stack_version}-datanucleus</name>
            </package>
            <!--  TODO CRH livy2
            <package>
              <name>livy2_${stack_version}</name>
            </package>
            -->
          </packages>
        </osSpecific>
      </osSpecifics>

    </service>
  </services>
</metainfo>
